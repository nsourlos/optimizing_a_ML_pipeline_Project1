# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

This dataset contains data of customers that are targeted by banks to make a fixed term deposit with them. We seek to predict if each customer will subscribe in that scheme or not (https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-first-experiment-automated-ml)

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

The best performing model, which had the highest accuracy, was the ‘VotingEnsemble’, which takes the majority vote of many algorithms.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

We first download the data and create a dataframe based on them. We then clean the data and perform one hot encoding. We split the dataset into train and test sets (80-20% respectively) and train a logistic regression classifier with two hyperparameters, the maximum number of iterations (max_iter) and the inverse regularization parameter (C). 

We then use an SKLearn estimator and a random parameter sampler and feed them to hyperdrivevconfig. The metric we used was accuracy.

**What are the benefits of the parameter sampler you chose?**

Random sampling allows to reduce the computational time needed to get results and achieves almost as good results as grid search. 

**What are the benefits of the early stopping policy you chose?**

In general, an early termination policy prevents experiments from running for a long time and using up resources. In our case we check every 2 iterations if the primary metric falls outside the top 10 percent of the best results and if it does we terminate the job.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

In AutoML many different models with different normalization and scaling techniques were used. Models like XGBoostClassifier, RandomForest and LogisticRegression were used, whereas some of the techniques are MAXAbsScaler, SparseNormalizer and StandardScalerNormalizer. The parameters used in AutoML are the ‘experiment_timeout_hours’ which is Maximum amount of time in hours that all iterations combined can take before the experiment terminates, we defined that we have a classification task that we need to perform and we defined the training data and the label column, and we also defined the metric that we need to optimize (accuracy). We also specified the number of cross validations that we want to perform and that the model should be onnx compatible to save it below.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

The accuracy achieved by HyperDrive was around 90.7% whereas AutoML achieved almost 91.8%. This is because HyperDrive only uses one model, LogisticClassifier, whereas AutoML uses many models and at the end, takes their ensemble. 

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

Try different combinations/values for the parameters in random sampling (or even try other sampling methods like Bayesian Sampling), add more total runs, use ‘AUC_weighted’ and other metrics instead of accuracy, apply methods to combat class imbalance issues (alert generated in AutoML runs), increase experiment timeout in AutoML to perform more runs/experiments.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**

![alt text](https://github.com/nsourlos/optimizing_a_ML_pipeline_Project1 /blob/main/deletion.png)
