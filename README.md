# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

This dataset contains data of customers that are targeted by banks to make a fixed term deposit with them. We seek to predict if each customer will subscribe in that scheme or not (https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-first-experiment-automated-ml)

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

...........

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

We first download the data and create a dataframe based on them. We then clean the data and perform one hot encoding. We then split the dataset into train and test sets (80-20% respectively) and train a logistic regression classifier with two hyperparameters, the maximum number of iterations (max_iter) and the inverse regularization parameter (C). 

We then use an SKLearn estimator and a random parameter sampler and feed them to hyperdrivevconfig. 

**What are the benefits of the parameter sampler you chose?**

Random sampling allows to reduce the computational time needed to get results and achieves almost as good results as grid search. 

**What are the benefits of the early stopping policy you chose?**

In general, an early termination policy prevents experiments from running for a long time and using up resources. In our case we check every 2 iterations if the primary metric falls outside the top 10 percent os the results and if it does we terminate the job.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

Try different combinations/values for the parameters in random sampling, add more total runs.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
